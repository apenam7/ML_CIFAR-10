{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-f643ac1e83e4>:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check that GPU is available: cf. https://colab.research.google.com/notebooks/gpu.ipynb\n",
    "assert(tf.test.is_gpu_available())\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.config.optimizer.set_jit(False) # Start with XLA disabled.\n",
    "\n",
    "def load_data():\n",
    "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "  x_train = x_train.astype('float32') / 256\n",
    "  x_test = x_test.astype('float32') / 256\n",
    "\n",
    "  # Convert class vectors to binary class matrices.\n",
    "  y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "  y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "  return ((x_train, y_train), (x_test, y_test))\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.23046875 0.2421875  0.24609375]\n",
      "   [0.16796875 0.1796875  0.17578125]\n",
      "   [0.1953125  0.1875     0.16796875]\n",
      "   ...\n",
      "   [0.6171875  0.515625   0.421875  ]\n",
      "   [0.59375    0.48828125 0.3984375 ]\n",
      "   [0.578125   0.484375   0.40234375]]\n",
      "\n",
      "  [[0.0625     0.078125   0.078125  ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.0703125  0.03125    0.        ]\n",
      "   ...\n",
      "   [0.48046875 0.34375    0.21484375]\n",
      "   [0.46484375 0.32421875 0.1953125 ]\n",
      "   [0.4765625  0.33984375 0.22265625]]\n",
      "\n",
      "  [[0.09765625 0.09375    0.08203125]\n",
      "   [0.0625     0.02734375 0.        ]\n",
      "   [0.19140625 0.10546875 0.03125   ]\n",
      "   ...\n",
      "   [0.4609375  0.328125   0.1953125 ]\n",
      "   [0.46875    0.328125   0.1953125 ]\n",
      "   [0.42578125 0.28515625 0.1640625 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8125     0.6640625  0.375     ]\n",
      "   [0.78515625 0.59765625 0.1328125 ]\n",
      "   [0.7734375  0.62890625 0.1015625 ]\n",
      "   ...\n",
      "   [0.625      0.51953125 0.2734375 ]\n",
      "   [0.21875    0.12109375 0.02734375]\n",
      "   [0.20703125 0.1328125  0.078125  ]]\n",
      "\n",
      "  [[0.703125   0.54296875 0.375     ]\n",
      "   [0.67578125 0.48046875 0.1640625 ]\n",
      "   [0.7265625  0.5625     0.1171875 ]\n",
      "   ...\n",
      "   [0.71875    0.578125   0.3671875 ]\n",
      "   [0.37890625 0.2421875  0.1328125 ]\n",
      "   [0.32421875 0.20703125 0.1328125 ]]\n",
      "\n",
      "  [[0.69140625 0.5625     0.453125  ]\n",
      "   [0.65625    0.50390625 0.3671875 ]\n",
      "   [0.69921875 0.5546875  0.33984375]\n",
      "   ...\n",
      "   [0.84375    0.71875    0.546875  ]\n",
      "   [0.58984375 0.4609375  0.328125  ]\n",
      "   [0.48046875 0.359375   0.28125   ]]]\n",
      "\n",
      "\n",
      " [[[0.6015625  0.69140625 0.73046875]\n",
      "   [0.4921875  0.53515625 0.53125   ]\n",
      "   [0.41015625 0.40625    0.37109375]\n",
      "   ...\n",
      "   [0.35546875 0.37109375 0.27734375]\n",
      "   [0.33984375 0.3515625  0.27734375]\n",
      "   [0.30859375 0.31640625 0.2734375 ]]\n",
      "\n",
      "  [[0.546875   0.625      0.66015625]\n",
      "   [0.56640625 0.59765625 0.6015625 ]\n",
      "   [0.48828125 0.48828125 0.4609375 ]\n",
      "   ...\n",
      "   [0.375      0.38671875 0.3046875 ]\n",
      "   [0.30078125 0.3125     0.2421875 ]\n",
      "   [0.27734375 0.28515625 0.23828125]]\n",
      "\n",
      "  [[0.546875   0.60546875 0.640625  ]\n",
      "   [0.54296875 0.5703125  0.58203125]\n",
      "   [0.44921875 0.44921875 0.4375    ]\n",
      "   ...\n",
      "   [0.30859375 0.3203125  0.25      ]\n",
      "   [0.265625   0.2734375  0.21484375]\n",
      "   [0.26171875 0.26953125 0.21484375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.68359375 0.65234375 0.6484375 ]\n",
      "   [0.609375   0.6015625  0.625     ]\n",
      "   [0.6015625  0.625      0.6640625 ]\n",
      "   ...\n",
      "   [0.1640625  0.1328125  0.140625  ]\n",
      "   [0.23828125 0.20703125 0.22265625]\n",
      "   [0.36328125 0.32421875 0.35546875]]\n",
      "\n",
      "  [[0.64453125 0.6015625  0.5       ]\n",
      "   [0.609375   0.59375    0.5078125 ]\n",
      "   [0.62109375 0.62890625 0.5546875 ]\n",
      "   ...\n",
      "   [0.40234375 0.36328125 0.375     ]\n",
      "   [0.48046875 0.4453125  0.46875   ]\n",
      "   [0.51171875 0.47265625 0.51171875]]\n",
      "\n",
      "  [[0.63671875 0.578125   0.46875   ]\n",
      "   [0.6171875  0.578125   0.4765625 ]\n",
      "   [0.63671875 0.609375   0.51953125]\n",
      "   ...\n",
      "   [0.55859375 0.51953125 0.54296875]\n",
      "   [0.55859375 0.5234375  0.5546875 ]\n",
      "   [0.55859375 0.51953125 0.5625    ]]]\n",
      "\n",
      "\n",
      " [[[0.99609375 0.99609375 0.99609375]\n",
      "   [0.98828125 0.98828125 0.98828125]\n",
      "   [0.98828125 0.98828125 0.98828125]\n",
      "   ...\n",
      "   [0.98828125 0.98828125 0.98828125]\n",
      "   [0.98828125 0.98828125 0.98828125]\n",
      "   [0.98828125 0.98828125 0.98828125]]\n",
      "\n",
      "  [[0.99609375 0.99609375 0.99609375]\n",
      "   [0.99609375 0.99609375 0.99609375]\n",
      "   [0.99609375 0.99609375 0.99609375]\n",
      "   ...\n",
      "   [0.99609375 0.99609375 0.99609375]\n",
      "   [0.99609375 0.99609375 0.99609375]\n",
      "   [0.99609375 0.99609375 0.99609375]]\n",
      "\n",
      "  [[0.99609375 0.99609375 0.99609375]\n",
      "   [0.9921875  0.9921875  0.9921875 ]\n",
      "   [0.9921875  0.9921875  0.9921875 ]\n",
      "   ...\n",
      "   [0.9921875  0.9921875  0.9921875 ]\n",
      "   [0.9921875  0.9921875  0.9921875 ]\n",
      "   [0.9921875  0.9921875  0.9921875 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.44140625 0.46875    0.4375    ]\n",
      "   [0.43359375 0.4609375  0.43359375]\n",
      "   [0.41015625 0.4375     0.4140625 ]\n",
      "   ...\n",
      "   [0.28125    0.31640625 0.3125    ]\n",
      "   [0.28125    0.3125     0.30859375]\n",
      "   [0.28125    0.3125     0.30859375]]\n",
      "\n",
      "  [[0.43359375 0.4609375  0.4296875 ]\n",
      "   [0.40625    0.43359375 0.40625   ]\n",
      "   [0.38671875 0.4140625  0.3828125 ]\n",
      "   ...\n",
      "   [0.265625   0.29296875 0.28515625]\n",
      "   [0.2734375  0.296875   0.29296875]\n",
      "   [0.3046875  0.328125   0.3203125 ]]\n",
      "\n",
      "  [[0.4140625  0.44140625 0.41015625]\n",
      "   [0.38671875 0.4140625  0.3828125 ]\n",
      "   [0.37109375 0.3984375  0.3671875 ]\n",
      "   ...\n",
      "   [0.3046875  0.33203125 0.32421875]\n",
      "   [0.30859375 0.33203125 0.32421875]\n",
      "   [0.3125     0.3359375  0.328125  ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.13671875 0.6953125  0.91796875]\n",
      "   [0.15625    0.6875     0.93359375]\n",
      "   [0.1640625  0.6875     0.94140625]\n",
      "   ...\n",
      "   [0.38671875 0.69140625 0.85546875]\n",
      "   [0.30859375 0.57421875 0.76953125]\n",
      "   [0.34765625 0.578125   0.73828125]]\n",
      "\n",
      "  [[0.22265625 0.7109375  0.9140625 ]\n",
      "   [0.171875   0.71875    0.9765625 ]\n",
      "   [0.1953125  0.71484375 0.9375    ]\n",
      "   ...\n",
      "   [0.609375   0.7109375  0.78125   ]\n",
      "   [0.55078125 0.69140625 0.8046875 ]\n",
      "   [0.453125   0.58203125 0.68359375]]\n",
      "\n",
      "  [[0.3828125  0.76953125 0.92578125]\n",
      "   [0.25       0.73828125 0.984375  ]\n",
      "   [0.26953125 0.75       0.95703125]\n",
      "   ...\n",
      "   [0.734375   0.76171875 0.8046875 ]\n",
      "   [0.46484375 0.52734375 0.57421875]\n",
      "   [0.23828125 0.30859375 0.3515625 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.28515625 0.30859375 0.30078125]\n",
      "   [0.20703125 0.24609375 0.265625  ]\n",
      "   [0.2109375  0.265625   0.3125    ]\n",
      "   ...\n",
      "   [0.06640625 0.15625    0.25      ]\n",
      "   [0.08203125 0.140625   0.19921875]\n",
      "   [0.12890625 0.1875     0.19140625]]\n",
      "\n",
      "  [[0.23828125 0.265625   0.29296875]\n",
      "   [0.21484375 0.2734375  0.3359375 ]\n",
      "   [0.22265625 0.30859375 0.40234375]\n",
      "   ...\n",
      "   [0.09375    0.1875     0.28125   ]\n",
      "   [0.06640625 0.13671875 0.20703125]\n",
      "   [0.02734375 0.08984375 0.125     ]]\n",
      "\n",
      "  [[0.171875   0.21875    0.28515625]\n",
      "   [0.1796875  0.2578125  0.34375   ]\n",
      "   [0.19140625 0.30078125 0.41015625]\n",
      "   ...\n",
      "   [0.10546875 0.203125   0.30078125]\n",
      "   [0.08203125 0.16796875 0.2578125 ]\n",
      "   [0.046875   0.12109375 0.1953125 ]]]\n",
      "\n",
      "\n",
      " [[[0.73828125 0.82421875 0.9375    ]\n",
      "   [0.7265625  0.8125     0.921875  ]\n",
      "   [0.72265625 0.80859375 0.91796875]\n",
      "   ...\n",
      "   [0.68359375 0.76171875 0.875     ]\n",
      "   [0.671875   0.7578125  0.8671875 ]\n",
      "   [0.66015625 0.7578125  0.859375  ]]\n",
      "\n",
      "  [[0.7578125  0.8203125  0.93359375]\n",
      "   [0.74609375 0.80859375 0.921875  ]\n",
      "   [0.7421875  0.8046875  0.91796875]\n",
      "   ...\n",
      "   [0.67578125 0.75       0.859375  ]\n",
      "   [0.66796875 0.74609375 0.8515625 ]\n",
      "   [0.65234375 0.7421875  0.84375   ]]\n",
      "\n",
      "  [[0.8125     0.85546875 0.953125  ]\n",
      "   [0.80078125 0.84375    0.9375    ]\n",
      "   [0.796875   0.83984375 0.93359375]\n",
      "   ...\n",
      "   [0.68359375 0.74609375 0.84765625]\n",
      "   [0.671875   0.7421875  0.84375   ]\n",
      "   [0.66015625 0.74609375 0.83984375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.80859375 0.77734375 0.70703125]\n",
      "   [0.79296875 0.76171875 0.68359375]\n",
      "   [0.79296875 0.765625   0.67578125]\n",
      "   ...\n",
      "   [0.52734375 0.515625   0.49609375]\n",
      "   [0.6328125  0.6171875  0.5859375 ]\n",
      "   [0.65625    0.63671875 0.58984375]]\n",
      "\n",
      "  [[0.7734375  0.7421875  0.6640625 ]\n",
      "   [0.73828125 0.70703125 0.62109375]\n",
      "   [0.703125   0.671875   0.57421875]\n",
      "   ...\n",
      "   [0.6953125  0.66796875 0.625     ]\n",
      "   [0.68359375 0.66015625 0.609375  ]\n",
      "   [0.68359375 0.66015625 0.6015625 ]]\n",
      "\n",
      "  [[0.7734375  0.73828125 0.67578125]\n",
      "   [0.73828125 0.70703125 0.6328125 ]\n",
      "   [0.6953125  0.6640625  0.58203125]\n",
      "   ...\n",
      "   [0.76171875 0.71875    0.66015625]\n",
      "   [0.765625   0.73828125 0.66796875]\n",
      "   [0.76171875 0.7421875  0.66796875]]]\n",
      "\n",
      "\n",
      " [[[0.89453125 0.89453125 0.93359375]\n",
      "   [0.921875   0.92578125 0.96484375]\n",
      "   [0.9140625  0.921875   0.96484375]\n",
      "   ...\n",
      "   [0.84765625 0.85546875 0.91015625]\n",
      "   [0.86328125 0.87109375 0.9140625 ]\n",
      "   [0.8671875  0.87109375 0.91015625]]\n",
      "\n",
      "  [[0.8671875  0.86328125 0.89453125]\n",
      "   [0.93359375 0.93359375 0.97265625]\n",
      "   [0.91015625 0.9140625  0.9609375 ]\n",
      "   ...\n",
      "   [0.87109375 0.87109375 0.921875  ]\n",
      "   [0.88671875 0.890625   0.9296875 ]\n",
      "   [0.8203125  0.82421875 0.859375  ]]\n",
      "\n",
      "  [[0.83203125 0.8046875  0.82421875]\n",
      "   [0.9140625  0.90625    0.93359375]\n",
      "   [0.90234375 0.91015625 0.953125  ]\n",
      "   ...\n",
      "   [0.859375   0.859375   0.90625   ]\n",
      "   [0.859375   0.85546875 0.90625   ]\n",
      "   [0.7890625  0.79296875 0.83984375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5859375  0.55859375 0.52734375]\n",
      "   [0.546875   0.52734375 0.49609375]\n",
      "   [0.515625   0.49609375 0.46875   ]\n",
      "   ...\n",
      "   [0.875      0.8671875  0.8515625 ]\n",
      "   [0.8984375  0.890625   0.87890625]\n",
      "   [0.94140625 0.94140625 0.9296875 ]]\n",
      "\n",
      "  [[0.53515625 0.515625   0.4921875 ]\n",
      "   [0.5078125  0.49609375 0.46875   ]\n",
      "   [0.48828125 0.47265625 0.44921875]\n",
      "   ...\n",
      "   [0.70703125 0.703125   0.6953125 ]\n",
      "   [0.7890625  0.78515625 0.7734375 ]\n",
      "   [0.828125   0.82421875 0.80859375]]\n",
      "\n",
      "  [[0.4765625  0.46484375 0.4453125 ]\n",
      "   [0.4609375  0.453125   0.4296875 ]\n",
      "   [0.46875    0.453125   0.43359375]\n",
      "   ...\n",
      "   [0.69921875 0.69140625 0.67578125]\n",
      "   [0.640625   0.640625   0.6328125 ]\n",
      "   [0.63671875 0.63671875 0.62890625]]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from keras.datasets import cifar10\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same'),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3)),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "  ])\n",
    "\n",
    "model = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "50000/50000 [==============================] - 14s 281us/sample - loss: 2.0458 - accuracy: 0.2542 - val_loss: 1.7722 - val_accuracy: 0.3806\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 9s 185us/sample - loss: 2.1345 - accuracy: 0.2117 - val_loss: 1.8806 - val_accuracy: 0.3368\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 9s 185us/sample - loss: 1.7852 - accuracy: 0.3593 - val_loss: 1.6491 - val_accuracy: 0.4163\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 9s 186us/sample - loss: 1.6493 - accuracy: 0.4046 - val_loss: 1.5709 - val_accuracy: 0.4416\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 9s 187us/sample - loss: 1.5651 - accuracy: 0.4352 - val_loss: 1.4745 - val_accuracy: 0.4754\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 9s 186us/sample - loss: 1.5023 - accuracy: 0.4590 - val_loss: 1.4032 - val_accuracy: 0.5021\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 9s 186us/sample - loss: 1.4507 - accuracy: 0.4765 - val_loss: 1.4178 - val_accuracy: 0.4968\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 9s 186us/sample - loss: 1.4022 - accuracy: 0.4940 - val_loss: 1.3235 - val_accuracy: 0.5281\n",
      "Epoch 8/25\n",
      "47616/50000 [===========================>..] - ETA: 0s - loss: 1.3701 - accuracy: 0.5085"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-9b193e921d21>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, x_train, y_train, x_test, y_test, epochs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m   \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf_cnn\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 147us/sample - loss: 1.2875 - accuracy: 0.5418\n",
      "Test loss: 1.287472003173828\n",
      "Test accuracy: 0.5418\n"
     ]
    }
   ],
   "source": [
    "def compile_model(model):\n",
    "  opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=opt,\n",
    "                metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "model = compile_model(model)\n",
    "\n",
    "def train_model(model, x_train, y_train, x_test, y_test, epochs=25):\n",
    "  model.fit(x_train, y_train, batch_size=256, epochs=epochs, validation_data=(x_test, y_test), shuffle=True)\n",
    "\n",
    "def warmup(model, x_train, y_train, x_test, y_test):\n",
    "  # Warm up the JIT, we do not wish to measure the compilation time.\n",
    "  initial_weights = model.get_weights()\n",
    "  train_model(model, x_train, y_train, x_test, y_test, epochs=1)\n",
    "  model.set_weights(initial_weights)\n",
    "\n",
    "warmup(model, x_train, y_train, x_test, y_test)\n",
    "%time train_model(model, x_train, y_train, x_test, y_test)\n",
    "\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cnn",
   "language": "python",
   "name": "tf_cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
